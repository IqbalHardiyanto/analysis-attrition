# -*- coding: utf-8 -*-
"""Submission Pertama: Menyelesaikan Permasalahan Human Resources.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Umr9TjujMBVsWJ8PkhiR-bl21wHfu06Z

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Muh. Iqbal Hardiyanto
- Email: muhiqbal1059@gmail.com
- Id Dicoding: miqbal_h

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from scipy import stats
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score

import warnings
warnings.filterwarnings('ignore')

"""### Menyiapkan data yang akan diguankan

## Data Understanding
"""

df_emp = pd.read_csv('/content/employee_data.csv')
print("Data Overview:")
df_emp.head()

print("Data Shape:", df_emp.shape)

print("\nData Types:")
df_emp.dtypes

print("\nData Info:")
df_emp.info()

print("\nMissing Values Before Handling:")
print(df_emp.isnull().sum())

print("\nAnalisis Deskriptif:\n")
print(df_emp.describe(include='all'))

"""### Exploratory Data Analysis (EDA)"""

print(df_emp['Attrition'].unique())

print("\nAttrition Value Counts:")
print(df_emp['Attrition'].value_counts(dropna=False))

print("\nAttrition Ratio:")
print(df_emp['Attrition'].value_counts(normalize=True))

# Hitung jumlah attrition berdasarkan job satisfaction
df_attrition_jobs = df_emp.groupby('JobSatisfaction')['Attrition'].value_counts().unstack()
df_attrition_jobs

# Menampilkan nama masing-masing pekerjaan dari setiap departemen

# Mengelompokkan data berdasarkan departemen dan pekerjaan, kemudian menjumlahkannya
job_names = df_emp.groupby(['Department', 'JobRole'])['EmployeeId'].count().reset_index()
job_names = job_names.rename(columns={'EmployeeId': 'jumlah_karyawan'})

# Menampilkan hasil
job_names

# Distribution analysis
plt.figure(figsize=(10, 6))
sns.histplot(df_emp['Age'], kde=True, color='skyblue')
plt.title('Distribusi Umur', fontsize=16)
plt.xlabel('Umur')
plt.ylabel('Jumlah Karyawan')
plt.show()

# Distribusi Attrition
attrition_counts = df_emp['Attrition'].value_counts()
plt.figure(figsize=(8, 5))
sns.barplot(
    x=attrition_counts.index,
    y=attrition_counts.values,
    hue=attrition_counts.index, # Ini akan membuat warna berbeda untuk 'Yes' dan 'No'
    palette='coolwarm',
    legend=False
)
plt.title('Distribusi Attrition', fontsize=12)
plt.xlabel('Attrition')
plt.ylabel('Count')
plt.show()

# Income vs Attrition
plt.figure(figsize=(10,6))
sns.boxplot(
    x='Attrition',
    y='MonthlyIncome',
    data=df_emp,
    hue='Attrition',
    palette='coolwarm',
    showfliers=False,
    legend=False
)
plt.title('Monthly Income vs Attrition', fontsize=12)
plt.xlabel('Attrition')
plt.ylabel('Monthly Income')
plt.xticks([0, 1], ['No', 'Yes'])
plt.show()

# Correlation matrix
plt.figure(figsize=(14, 10))
numerical_df = df_emp.select_dtypes(include=['number'])
correlation_matrix = numerical_df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix Heatmap')
plt.show()

# Department-wise attrition
plt.figure(figsize=(12,8))
sns.countplot(x='Department', hue='Attrition', data=df_emp, palette='coolwarm')
plt.title('Attrition by Department', fontsize=16)
plt.xlabel('Department')
plt.ylabel('Count')
plt.legend(title='Attrition', labels=['No', 'Yes'])
plt.show()

# Job Satisfaction vs Attrition
plt.figure(figsize=(12,6))
sns.countplot(x='JobSatisfaction', hue='Attrition', data=df_emp, palette='coolwarm')
plt.title('Job Satisfaction vs Attrition', fontsize=16)
plt.xlabel('Job Satisfaction Level')
plt.ylabel('Count')
plt.legend(title='Attrition', labels=['No', 'Yes'])
plt.show()

"""## Data Preparation / Preprocessing

"""

attrition_mapping = {
    'Yes': 1, 'yes': 1, 'YES': 1, '1': 1, 1.0: 1, '1.0': 1,
    'No': 0, 'no': 0, 'NO': 0, '0': 0, 0.0: 0, '0.0': 0
}
# Konversi target 'Attrition' ke Biner
df_emp['Attrition'] = df_emp['Attrition'].map(attrition_mapping)

# Handling missing values
df_emp = df_emp.dropna(subset = ['Attrition'])

df_emp['Attrition'] = df_emp['Attrition'].astype(int)

# Cek hasil
print("\nMissing Values After Cleaning:")
print(df_emp.isnull().sum())
print("\nAttrition Distribution After Cleaning:")
print(df_emp['Attrition'].value_counts(normalize=True))

"""### Feature Selection and Data Splitting"""

# Buat salinan data untuk diproses
data_emp_processed = df_emp.copy()

# Definisikan fitur yang akan digunakan (X) dan target (y)
features_to_use = [
    'Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',
    'Education', 'EducationField', 'Gender', 'HourlyRate', 'JobInvolvement',
    'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome',
    'MonthlyRate', 'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike',
    'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',
    'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',
    'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
]

"""### SMOTE dan Scalling"""

X = data_emp_processed[features_to_use]
y = data_emp_processed['Attrition']

# Split data sebelum preprocessing untuk menghindari data leakage
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )


print(f"\nShape of X_train: {X_train.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of y_test: {y_test.shape}")

"""### Pipeline Preprocessing"""

# Identifikasi kolom numerik dan kategorikal
numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()

print(f"\nNumerical features: {numeric_features}")
print(f"Categorical features: {categorical_features}")

# Pipeline untuk fitur numerik
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Pipeline untuk fitur kategorikal
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Gabungkan transformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='passthrough'
)

# Preprocessing data training dan testing
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

print(f"\nShape of X_train_processed: {X_train_processed.shape}")
print(f"Shape of X_test_processed: {X_test_processed.shape}")

"""### Handling Class Imbalance with SMOTE"""

# Menerapkan SMOTE hanya pada data training
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)

print(f"\nShape of X_train_resampled after SMOTE: {X_train_resampled.shape}")
print(f"Shape of y_train_resampled after SMOTE: {y_train_resampled.shape}")

# Cek distribusi kelas setelah SMOTE
print("\nClass distribution in y_train_resampled after SMOTE:")
print(pd.Series(y_train_resampled).value_counts())

"""## Modeling

"""

# Menerapkan pengklasifikasi model klasifikasi

# Definisikan model dan parameter grid untuk SVM
svm_param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto', 0.1, 1]
}

# Menerapkan pengklasifikasi
classifiers = {
    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),
    'RandomForest': RandomForestClassifier(
        n_estimators=800,
        max_depth=49,
        min_samples_split=3,
        min_samples_leaf=1,
        random_state=42,
    ),
    'SVM': GridSearchCV(
        SVC(probability=True, random_state=42),
        param_grid=svm_param_grid,
        cv=3,
        scoring='f1',
        n_jobs=-1
    )
}

# Latih dan evaluasi model
model_results = {}

for name, model in classifiers.items():
    print(f"\nTraining {name}...")

    # Latih model
    if name == 'SVM':
        model.fit(X_train_resampled, y_train_resampled)
        best_model = model.best_estimator_
        print(f"Best parameters for SVM: {model.best_params_}")
    else:
        model.fit(X_train_resampled, y_train_resampled)
        best_model = model

    # Prediksi pada data test
    y_pred_test = best_model.predict(X_test_processed)
    y_pred_proba_test = best_model.predict_proba(X_test_processed)[:, 1] if hasattr(best_model, "predict_proba") else None

    # Evaluasi model
    accuracy_test = accuracy_score(y_test, y_pred_test)
    precision_test = precision_score(y_test, y_pred_test)
    recall_test = recall_score(y_test, y_pred_test)
    f1_test = f1_score(y_test, y_pred_test)
    report_dict_test = classification_report(y_test, y_pred_test, output_dict=True)
    report_str_test = classification_report(y_test, y_pred_test)

    model_results[name] = {
        'model': best_model,
        'accuracy': accuracy_test,
        'precision': precision_test,
        'recall': recall_test,
        'f1_score': f1_test,
        'report_dict': report_dict_test,
        'report_str': report_str_test,
        'y_pred': y_pred_test,
        'y_pred_proba': y_pred_proba_test
    }

    # Print hasil evaluasi
    print(f"{name} Test Accuracy: {accuracy_test:.4f}")
    print(f"{name} Test F1 Score: {f1_test:.4f}")
    print("="*50)
    print(f"{name} Test Classification Report:\n{report_str_test}\n")

"""## Evaluation

### Logistic Regression
"""

accuracy_lr = model_results['LogisticRegression']['accuracy']
f1_score_lr = model_results['LogisticRegression']['f1_score']

print(f"Logistic Regression Accuracy: {accuracy_lr:.4f}")
print(f"Logistic Regression F1 Score: {f1_score_lr:.4f}")
print(f"Logistic Regression Classification Report:\n{model_results['LogisticRegression']['report_str']}")

# Visualisasi Confussion Matrix
y_pred_lr = model_results['LogisticRegression']['y_pred']
cfmx_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(8,6))
sns.heatmap(cfmx_lr, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression', fontsize=14)
plt.xlabel('Predicted')
plt.ylabel('True Label')
plt.show()

"""### Random Forest"""

accuracy_rf = model_results['RandomForest']['accuracy']
f1_score_rf = model_results['RandomForest']['f1_score']

print(f"Random Forest Accuracy: {accuracy_rf:.4f}")
print(f"Random Forest F1 Score: {f1_score_rf:.4f}")
print(f"Random Forest Classification Report:\n{model_results['RandomForest']['report_str']}")

# Visualisasi Confusion Matrix
y_pred_rf = model_results['RandomForest']['y_pred']
cfmx_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8,6))
sns.heatmap(cfmx_rf, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Random Forest', fontsize=14)
plt.xlabel('Predicted')
plt.ylabel('True Label')
plt.show()

"""### SVM"""

accuracy_svm = model_results['SVM']['accuracy']
f1_score_svm = model_results['SVM']['f1_score']

print(f"SVM Accuracy: {accuracy_svm:.4f}")
print(f"SVM F1 Score: {f1_score_svm:.4f}")
print(f"SVM Classification Report:\n{model_results['SVM']['report_str']}")

# Visualisasi Confusion Matrix
y_pred_svm = model_results['SVM']['y_pred']
cfmx_svm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(8,6))
sns.heatmap(cfmx_svm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - SVM', fontsize=14)
plt.xlabel('Predicted')
plt.ylabel('True Label')
plt.show()

"""### Evaluasi Model terbaik"""

best_model_name = None
best_f1_score = 0

for name, result in model_results.items():
    if result['f1_score'] > best_f1_score:
        best_f1_score = result['f1_score']
        best_model_name = name


print(f"\nModel terbaik: {best_model_name} dengan F1-score: {best_f1_score:.4f}")

# Visualisasi Confusion Matrix untuk semua model
for name, result in model_results.items():
    plt.figure(figsize=(6,4))
    cm = confusion_matrix(y_test, result['y_pred'])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=['No Attrition', 'Attrition'],
                yticklabels=['No Attrition', 'Attrition'])
    plt.title(f'Confusion Matrix - {name}', fontsize=14)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

# Feature Importance untuk model Random Forest
if best_model_name == 'RandomForest':
    print("\nFeature Importance for Random Forest:")
    try:
        feature_names = preprocessor.get_feature_names_out()
        importances = model_results['RandomForest']['model'].feature_importances_

        feature_importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importances
        }).sort_values(by='Importance', ascending=False)

        plt.figure(figsize=(10, max(6, len(feature_importance_df) // 3)))
        sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20), palette='viridis')
        plt.title('Feature Importance - Random Forest (Top 20)', fontsize=16)
        plt.xlabel('Importance')
        plt.ylabel('Feature')
        plt.tight_layout()
        plt.show()
        print("\nTop 10 Features:")
        print(feature_importance_df.head(10))

    except Exception as e:
        print(f"Error retrieving feature importances: {e}")

# Koefisien untuk Logistic Regression
if best_model_name == 'LogisticRegression':
    print("\nCoefficients for Logistic Regression:")
    try:
        feature_names = preprocessor.get_feature_names_out()
        coefficients = model_results['LogisticRegression']['model'].coef_[0]

        coeff_df = pd.DataFrame({
            'Feature': feature_names,
            'Coefficient': coefficients
        }).sort_values(by='Coefficient', key=abs, ascending=False)

        plt.figure(figsize=(10, max(6, len(coeff_df) // 3)))
        sns.barplot(x='Coefficient', y='Feature', data=coeff_df.head(20), palette='coolwarm')
        plt.title('Feature Coefficients - Logistic Regression (Top 20 by absolute value)', fontsize=16)
        plt.xlabel('Coefficient Value')
        plt.ylabel('Feature')
        plt.tight_layout()
        plt.show()
        print("\nTop 10 Coefficients (by absolute value):")
        print(coeff_df.head(10))

    except Exception as e:
        print(f"Error retrieving coefficients: {e}")

"""## Save Models"""

# Simpan semua model dan preprocessor dalam kedua format
for model_name in model_results:
    model = model_results[model_name]['model']

    # Simpan dalam format .pkl
    pkl_filename = f'{model_name}_model.pkl'
    joblib.dump(model, pkl_filename)

    # Simpan dalam format .joblib
    joblib_filename = f'{model_name}_model.joblib'
    joblib.dump(model, joblib_filename)

    print(f"Model '{model_name}' saved as {pkl_filename} and {joblib_filename}")

# Simpan preprocessor dalam kedua format
preprocessor_pkl = 'preprocessor.pkl'
preprocessor_joblib = 'preprocessor.joblib'

joblib.dump(preprocessor, preprocessor_pkl)
joblib.dump(preprocessor, preprocessor_joblib)

print(f"\nPreprocessor saved as {preprocessor_pkl} and {preprocessor_joblib}")

"""### Eksekusi Model dan Simpan Hasil Prediksi"""

# Fungsi untuk menjalankan prediksi dan menyimpan hasil
def predict_and_save_results(model_name, X_test, y_test, preprocessor, filename):
    model = joblib.load(f'{model_name}_model.pkl')
    X_test_processed = preprocessor.transform(X_test)
    y_pred = model.predict(X_test_processed)
    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]

    results_df = X_test.copy()
    results_df['Attrition_Actual'] = y_test.values
    results_df['Attrition_Predicted'] = y_pred
    results_df['Attrition_Probability'] = y_pred_proba

    # Simpan ke CSV
    results_df.to_csv(filename, index=False)
    print(f"Hasil prediksi disimpan sebagai {filename}")

    return results_df


for model_name in model_results.keys():
    filename = f'prediction_results_{model_name}.csv'
    results_df = predict_and_save_results(
        model_name,
        X_test,
        y_test,
        preprocessor,
        filename
    )

    # Tampilkan preview hasil
    print(f"\nPreview hasil untuk {model_name}:")
    print(results_df[['Attrition_Actual', 'Attrition_Predicted', 'Attrition_Probability']].head())